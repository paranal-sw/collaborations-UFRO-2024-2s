{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Naive Bayes and Sentiment Analysis to predict errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations at Paranal can end in three stages: STOP, ABORT by USER, ERROR (Aborted by system). Naive-Bayes models captures some of those events that leads to errors. In https://github.com/paranal-sw/parlogs-observations/blob/main/notebooks/04-naive-bayes.ipynb a simple Naive Bayes classificator is shown that predicts the df_meta[\"ERROR\"] column based on some simple tokenizations. \n",
    "\n",
    "But if you see, some messages are clearly an indication of errors, for example \n",
    "\n",
    "```\n",
    "issalignERR_EVT_TIMEOUT : TIMEOUT in sub-state <STRTLAG: Wait for IRIS Lab Guiding Event> while waiting for event.\n",
    "```\n",
    "\n",
    "The emotional tone of certain words like \"err\" or \"timeout\" could be captured by sentiment-analysis models and we believe that studying event logs by labelling its emotional tone in positive or negative could have predictive usefulness.\n",
    "\n",
    "\n",
    "\n",
    "## Objectives\n",
    "1. Dimensionality reduction, change the tokenization to remove all numbers using regexp. \n",
    "2. Train a Naive Bayes with all tokenized logs, not just logtype=ERR, and label the traces with a new \"NB\" column\n",
    "3. Search and apply some Sentiment Analysis models, label the traces with \"SA_1\", \"SA_2\"... ([hint](https://huggingface.co/blog/sentiment-analysis-python))\n",
    "4. Look for correlations in NB regarding the different values in \"SA_1\", \"SA_2\"...\n",
    "5. Report with specific examples of (events, NB score, SA score) to understand what is happening behind scenes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
